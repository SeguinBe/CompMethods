{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with real data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Let us assume you start with the excel file downloaded. You will first have to convert it to a more standard `.csv` format before being able to read it with pandas (actually it is possible to [read excel file](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) directly, but this is less standard and require additional installation).\n",
    "\n",
    "- Open the Excel file in Excel and `Save as` with the format being selected as `csv utf-8`. (if you do not have excel there is a csv already available next to the excel file)\n",
    "- Try loading it with the following command :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('my_csv_export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that there is a `ParserError` reading the file (assuming you have saved it properly and are referring to its name properly). This is because the file is actually not directly properly formatted.\n",
    "\n",
    "Open the `csv` file (right-click, open with) directly in a text editor (not Word or Wordpad!, but a pure text editor such as the Notepad, or much better VisualStudioCode).\n",
    "\n",
    "Remember that a `csv` should have the header line of the column names as the first row, and its values delimited by `,`. Looking at the file, and exploring the options of the `read_csv` function, can you correct the line below to properly load the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('my_csv_export.csv',\n",
    "            #header=??,\n",
    "            #delimiter=??\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "By default, the read data is not exactly clean so let us improve that.\n",
    "\n",
    "### Removing empty columns\n",
    "\n",
    "First, you might have noticed that there is a very large number of empty columns, which is an artifact of the export and the fact that there are very long values in the original excel file, which makes excel creates arbitrary empty columns to fit the long values in the display.\n",
    "\n",
    "This can be seen by listing the (more than 250) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the index object representing the names of all the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to remove them, we first need to detect them. Detecting missing values can be done by directly using the method `isna()`, but it will return another `pd.Series` describing missing value at every position, and not a single boolean for the whole column. In order to find columns where there is no interesting value in, have a look at the methods [`any()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.any.html) or [`all()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.all.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_column_empty(serie):\n",
    "    # Your code here\n",
    "    return False\n",
    "\n",
    "print(\"should be False : \", is_column_empty(df['School']))\n",
    "print(\"should be True : \", is_column_empty(df['Unnamed: 248']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous function, we can now remove the unnecessary columns. For this, simply iterate over the column names (with `df.columns` as seen above), and for each of them: test if they are empty and delete them if necessary.\n",
    "\n",
    "**HINT:** deleting column is the same syntax as deleting elements of a dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should evaluate to True if only the non-empty columns are left\n",
    "set(df.columns) == set(['School', 'Author', 'Actual Attributon', 'Place', 'Room', 'Title',\n",
    "       'Date', 'Date Acquired', 'Date Sold-Tranferred', 'Material / Technique',\n",
    "       'Size (cm)', 'N. Inv. Le Brun', 'Actual Location', 'ICONCLASS', '#',\n",
    "       '#.1', '#.2', '#.3', 'Link', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing types\n",
    "\n",
    "Pandas tries to convert the columns to the best data types and tries to separate categorical and numerical columns.\n",
    "\n",
    "Looking at the data in the `DataFrame` and the current data type (printed with the command below). Identify which column is not properly identified as being numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the listing of current columns with their associated data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, you can see directly in Excel or here that there is one value in that column can not be converted to numeric directly (line 14 to be exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date Acquired'][10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can create issues, for instance it is impossible to plot the joint plot of the dates of acquisition and selling. The following plotting command will give the appropriate error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('Date Acquired', 'Date Sold-Tranferred', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert a column to a numeric one, the function `pd.to_numeric` can be used. By default, it will fail because of the string value, look at the options of that function so that the wrong value is automatically dropped (by being converted to `np.nan`). \n",
    "\n",
    "Override the column in the `DataFrame` by assigning the converted column with the same name. (Reminder: it is still the same syntax as a dictionnary assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be True now\n",
    "df['Date Acquired'].dtype == np.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the jointplot should display properly.\n",
    "\n",
    "This visualization does not actually bring a lot of information as it only display the data points where both the acquisition date AND the selling date is known, which does not represent many data points.\n",
    "\n",
    "However, looking more closely at the previous plot, you might notice that some configurations do not seem possible and show wrong data. Can an object be sold before it is acquired???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('Date Acquired', 'Date Sold-Tranferred', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using filtering, display the two cases where the data is wrong (so that one could correct it in the original data file for instance, not necessary to correct it for the sake of this exercise though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the main Iconography\n",
    "\n",
    "Each record has a full ICONCLASS specification. [ICONCLASS](https://en.wikipedia.org/wiki/Iconclass) is a hierarchical iconographic classification system that is very involved. Here we take a simplistic approach and just extract the top-level (first digit) of the specification.\n",
    "\n",
    "### Installation of the iconclass python package\n",
    "\n",
    "In order to work with a more readable version of the ICONCLASS system, someone nicely made a python package that maps the obscure definitions to their textual representation.\n",
    "\n",
    "Installation can directly be done with the following command (special jupyter notebook shell command, starting with `!`) calling the python package manager `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install iconclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the newly installed package (needs to download a small database at the first import)\n",
    "import iconclass\n",
    "# Example usage\n",
    "iconclass.get('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package allow us to easily convert a ICONCLASS id to a dictionnary containing all the necessary information. The sub-classes in the tree of classification, the textual and keyword representation in multiple languages, and the parent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iconclass.get('11A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iconclass.get('11A(+5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple parsing: the ICONCLASS column\n",
    "\n",
    "Using this package we can now parse, for each record with an ICONCLASS value, its main category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_iconography(iconclass_string):\n",
    "    # Your code here\n",
    "    return 'Nothing'\n",
    "\n",
    "print('Should be \"Religion and Magic\" : ', extract_main_iconography(\"11 M 33\"))\n",
    "print('Should be \"Classical Mythology and Ancient History\" : ', extract_main_iconography(\"94 M 22 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `apply` method on the `ICONCLASS` column to create a new column with the textual value of the main iconography. Careful that you might need to filter the `NaN` values of the column before using `apply`.\n",
    "\n",
    "Add the created column to the original `DataFrame` with a name of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using seaborn `countplot` (or any other method), plot the distribution of records per iconography, what seemed to be the two most important genres?\n",
    "\n",
    "(Hint: depending on how you do it the labels of the plot might overlap each other making them unreadable. To rotate them, use `plt.xticks(rotation=90)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harder parsing : extracting the size information\n",
    "\n",
    "Since not every artwork is the same size, we want to not only measure the number of artworks owned at that time but also the surface they occupied.\n",
    "\n",
    "For this let us create a function that takes the information of size in the data and tries to separate the height and the width information. Using `split` and `replace` you should be able to parse all but 4 valid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_size(s):\n",
    "    try:\n",
    "        # Your code here\n",
    "        h, w = 0, 0\n",
    "        return h, w\n",
    "    except Exception as e:\n",
    "        print(f\"Can not parse: {s}\")\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "df['Size (cm)'].apply(parse_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is a bit complex so I give it to you directly\n",
    "df['Height'], df['Width'] = zip(*df['Size (cm)'].apply(parse_size))\n",
    "\n",
    "# Checking that the column has proper typing\n",
    "print('Should be True : ', df['Height'].dtype == np.float)\n",
    "print('Should be True : ', df['Width'].dtype == np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another variant in order to do the same thing but sligthly differently. Instead of using `apply` only on a column we use it direclty on the whold dataframe, and work on a full record (row). The same parsing code should then be used and we know return a dictionnary. This column of dictionnary is then `expanded` to directly make a new dataframe with the values of the two newly created columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_size_2(record):\n",
    "    s = record['Size (cm)']\n",
    "    try:\n",
    "        # Same code as above\n",
    "        h, w = 0, 0\n",
    "        return {'Height': h, 'Width': w}\n",
    "    except Exception as e:\n",
    "        print(f\"Can not parse: {s}\")\n",
    "        return {'Height': np.nan, 'Width': np.nan}\n",
    "\n",
    "# Generates directly a new DataFrame with two columns 'Height' and 'Width'. It can be added with `df.merge(...)`\n",
    "df.apply(parse_size_2, result_type='expand', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now separated properly the height and width of each painting. The area can then easily be computed and added as an additional column named 'Area'. Looking at the example below of how mathematical operators easily propagate on full columns, add the corresponding 'Area' column to the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df['Date Sold-Tranferred'] - df['Date Acquired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the `swarmplot` of seaborn, look at the distribution of the size of paintings according to their main iconography. What can you say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Aggregation\n",
    "\n",
    "In order to compute exactly the number of painting in each category and the combined areas of all the paintings in each category we need to aggregate the information.\n",
    "\n",
    "Try to use `groupby` on the Dataframe and then apply `sum` or `count` to create aggregated series. You might have to google a bit around to understand how `groupby` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then directly plot the aggregated values with `plot(kind='bar')` on the aggregated column. Display the aggregated count of records per iconographic category, and the aggregated area per iconographic category. Do they tell different stories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last questions\n",
    "\n",
    "### More precise analysis\n",
    "\n",
    "Of course, there is much more to be done that we are doing here. For instance can you adapt and rerun your code so that we display the statistics based on the second level iconography and not the top-level?\n",
    "\n",
    "What about the represented authors?\n",
    "\n",
    "### Sampling bias\n",
    "\n",
    "There are multiple records which are not in the final analysis, because one of the necessary field was not available or not parsed properly. Can you count the percentage of records missing in this analysis? Does it change the conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
